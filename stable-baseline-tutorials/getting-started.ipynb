{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-21T00:11:09.890145Z",
     "start_time": "2025-12-21T00:11:07.717885Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.a2c import MlpPolicy\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10_000)\n",
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "# Uncomment to watch the trained agent\n",
    "# for i in range(1000):\n",
    "#     action, _state = model.predict(obs, deterministic=True)\n",
    "#     obs, reward, done, info = vec_env.step(action)\n",
    "#     vec_env.render()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 23.4     |\n",
      "|    ep_rew_mean        | 23.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4672     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.693   |\n",
      "|    explained_variance | -0.0468  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -1.07    |\n",
      "|    value_loss         | 20.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 25.4     |\n",
      "|    ep_rew_mean        | 25.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4592     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.682   |\n",
      "|    explained_variance | 0.0792   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.62     |\n",
      "|    value_loss         | 7.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 29.4     |\n",
      "|    ep_rew_mean        | 29.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4664     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.658   |\n",
      "|    explained_variance | 0.036    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.48     |\n",
      "|    value_loss         | 6.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 31.4     |\n",
      "|    ep_rew_mean        | 31.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4645     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.66    |\n",
      "|    explained_variance | 0.00639  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 1.33     |\n",
      "|    value_loss         | 5.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 34.5     |\n",
      "|    ep_rew_mean        | 34.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4668     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.596   |\n",
      "|    explained_variance | -0.00263 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.11     |\n",
      "|    value_loss         | 5.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38       |\n",
      "|    ep_rew_mean        | 38       |\n",
      "| time/                 |          |\n",
      "|    fps                | 4674     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.642   |\n",
      "|    explained_variance | -0.00218 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    value_loss         | 4.79     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 41.7      |\n",
      "|    ep_rew_mean        | 41.7      |\n",
      "| time/                 |           |\n",
      "|    fps                | 4664      |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.596    |\n",
      "|    explained_variance | -0.000204 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 1.11      |\n",
      "|    value_loss         | 4.22      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 44.8     |\n",
      "|    ep_rew_mean        | 44.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4670     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.588   |\n",
      "|    explained_variance | 0.0019   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    value_loss         | 3.65     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 48.3      |\n",
      "|    ep_rew_mean        | 48.3      |\n",
      "| time/                 |           |\n",
      "|    fps                | 4687      |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.521    |\n",
      "|    explained_variance | -0.000282 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -12.1     |\n",
      "|    value_loss         | 1.13e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 50.1     |\n",
      "|    ep_rew_mean        | 50.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4698     |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.543   |\n",
      "|    explained_variance | -0.00025 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.901    |\n",
      "|    value_loss         | 2.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 54       |\n",
      "|    ep_rew_mean        | 54       |\n",
      "| time/                 |          |\n",
      "|    fps                | 4704     |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.536   |\n",
      "|    explained_variance | 0.00128  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.884    |\n",
      "|    value_loss         | 2.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 58.3     |\n",
      "|    ep_rew_mean        | 58.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4718     |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.394   |\n",
      "|    explained_variance | -0.00168 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    value_loss         | 1.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 61.8     |\n",
      "|    ep_rew_mean        | 61.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4711     |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.568   |\n",
      "|    explained_variance | 7.74e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.601    |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 65.7     |\n",
      "|    ep_rew_mean        | 65.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4695     |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.575   |\n",
      "|    explained_variance | -5.1e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.383    |\n",
      "|    value_loss         | 1.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 69.4     |\n",
      "|    ep_rew_mean        | 69.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4674     |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.551   |\n",
      "|    explained_variance | 0.00035  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.339    |\n",
      "|    value_loss         | 0.939    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 74       |\n",
      "|    ep_rew_mean        | 74       |\n",
      "| time/                 |          |\n",
      "|    fps                | 4673     |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.541   |\n",
      "|    explained_variance | 1.83e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.211    |\n",
      "|    value_loss         | 0.707    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 77.1     |\n",
      "|    ep_rew_mean        | 77.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4657     |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.26     |\n",
      "|    value_loss         | 0.496    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 80.8     |\n",
      "|    ep_rew_mean        | 80.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4648     |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.373   |\n",
      "|    explained_variance | 5.36e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.31     |\n",
      "|    value_loss         | 0.326    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 84.5     |\n",
      "|    ep_rew_mean        | 84.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 4650     |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.499   |\n",
      "|    explained_variance | 0.000154 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.176    |\n",
      "|    value_loss         | 0.186    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 88.2      |\n",
      "|    ep_rew_mean        | 88.2      |\n",
      "| time/                 |           |\n",
      "|    fps                | 4651      |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.517    |\n",
      "|    explained_variance | -1.78e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 0.182     |\n",
      "|    value_loss         | 0.0865    |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This getting started is provided from the following link: https://github.com/araffin/rl-tutorial-jnrr19/blob/sb3/1_getting_started.ipynb",
   "id": "a212d9a42d5ff8f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T00:17:32.893796Z",
     "start_time": "2025-12-21T00:17:32.880584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3 import PPO\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "model = PPO('MlpPolicy', env, verbose=0)"
   ],
   "id": "3c8f8ab53ec57332",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> Evaluating the agent using stable-baselines3 built-in function",
   "id": "6111ea8673fa65d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T00:19:14.177308Z",
     "start_time": "2025-12-21T00:19:14.060202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100, deterministic=True)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward}')"
   ],
   "id": "b23c2d3c4b39833f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 10.19 +/- 2.9247051133404893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geraldamasi/PycharmProjects/RL/.venv/lib/python3.13/site-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> Train the agent and evaluate it",
   "id": "c81367e2d7de97bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T00:19:59.296196Z",
     "start_time": "2025-12-21T00:19:57.355119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training an agent\n",
    "model.learn(total_timesteps=10_000)"
   ],
   "id": "e0b832a71ec10a14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x12e0c3b60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T00:20:12.860511Z",
     "start_time": "2025-12-21T00:20:09.789975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100, deterministic=True)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward}')"
   ],
   "id": "28b36b69590ad5cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 429.77 +/- 96.50076217315592\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> Training went well if mean reward increased alot",
   "id": "885694d5cdce2a9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare the video recording",
   "id": "7b4a5b0836b99273"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T00:23:19.153114Z",
     "start_time": "2025-12-21T00:23:19.141794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "def record_video(env_id, model, video_length=500, prefix=\"\", video_folder=\"videos/\"):\n",
    "    \"\"\"\n",
    "    :param env_id: (str)\n",
    "    :param model: (RL model)\n",
    "    :param video_length: (int)\n",
    "    :param prefix: (str)\n",
    "    :param video_folder: (str)\n",
    "    \"\"\"\n",
    "    eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
    "    # Start the video at step=0 and record 500 steps\n",
    "    eval_env = VecVideoRecorder(\n",
    "        eval_env,\n",
    "        video_folder=video_folder,\n",
    "        record_video_trigger=lambda step: step == 0,\n",
    "        video_length=video_length,\n",
    "        name_prefix=prefix,\n",
    "    )\n",
    "\n",
    "    obs = eval_env.reset()\n",
    "    for _ in range(video_length):\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, _, _, _ = eval_env.step(action)\n",
    "\n",
    "    # Close the video recorder\n",
    "    eval_env.close()"
   ],
   "id": "3327889fff06a335",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize the trained agent",
   "id": "1cb22c073dd5c45c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T00:25:23.341728Z",
     "start_time": "2025-12-21T00:25:19.868641Z"
    }
   },
   "cell_type": "code",
   "source": "record_video(env_id='CartPole-v1', model=model, video_length=500, prefix=\"ppo-cartpole\")",
   "id": "5579e67a9220bfd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving video to /Users/geraldamasi/PycharmProjects/RL/stable-baseline-tutorials/videos/ppo-cartpole-step-0-to-step-500.mp4\n",
      "MoviePy - Building video /Users/geraldamasi/PycharmProjects/RL/stable-baseline-tutorials/videos/ppo-cartpole-step-0-to-step-500.mp4.\n",
      "MoviePy - Writing video /Users/geraldamasi/PycharmProjects/RL/stable-baseline-tutorials/videos/ppo-cartpole-step-0-to-step-500.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /Users/geraldamasi/PycharmProjects/RL/stable-baseline-tutorials/videos/ppo-cartpole-step-0-to-step-500.mp4\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](videos/ppo-cartpole-step-0-to-step-500.mp4)",
   "id": "2e39e600ed3510e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train a model with only 1 line of code",
   "id": "74bef4cdb7ad8424"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T00:27:44.747500Z",
     "start_time": "2025-12-21T00:27:42.844462Z"
    }
   },
   "cell_type": "code",
   "source": "model = PPO('MlpPolicy', 'CartPole-v1', verbose=1).learn(total_timesteps=10_000)",
   "id": "5efdbd61f4108551",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Creating environment from the given name 'CartPole-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.9     |\n",
      "|    ep_rew_mean     | 22.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 10858    |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.9        |\n",
      "|    ep_rew_mean          | 27.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7242        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007652224 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | 0.00761     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.36        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.8        |\n",
      "|    ep_rew_mean          | 36.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6514        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009836028 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.0695      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.3        |\n",
      "|    ep_rew_mean          | 48.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6217        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010066026 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.641      |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 63.3        |\n",
      "|    ep_rew_mean          | 63.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6041        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008290639 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.608      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 69.5        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bb68534dde6cea9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
